{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89786d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable, Dict, List, Any\n",
    "from functools import partial\n",
    "from jaxopt import Bisection, FixedPointIteration\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "from scipy.stats import nbinom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb7927",
   "metadata": {},
   "source": [
    "We want to try to explain the results in Figure 3 using the implicit function method.\n",
    "We are considering the case of a negative binimial PGF which is given by\n",
    "$$G(x;R_0,\\kappa) =  \\bigg[ 1 + \\tfrac{R_0}\\kappa(1-x) \\bigg]^{-\\kappa -1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def G_nbinom(x: float, R0, k) -> float:\n",
    "    \"\"\"\n",
    "    Function to compute the negative binomial distribution.\n",
    "    \"\"\"\n",
    "    return (1 + R0/k * (1-x))**(-k)\n",
    "\n",
    "\n",
    "\n",
    "def nbinom_degree_sequence_non_vec(r0, k, N_max = 300):\n",
    "    n = k\n",
    "    p = k / (r0 + k) \n",
    "    #p = r0 / (r0 + k)  # Adjusted for the new parameterization\n",
    "    dist = nbinom(n=n, p=p)  # Scipy parameterizes with alpha / R0 + alpha\n",
    "    degree_sequence = dist.pmf(range(N_max + 1))\n",
    "    return degree_sequence\n",
    "\n",
    "def nbinom_degree_sequence(r0_row, k_row, N_max = 300):\n",
    "    return jax.vmap(lambda r0,k, N_max: nbinom_degree_sequence_non_vec(r0, k, N_max))(r0_row, k_row, N_max)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the Jax fixed point finder to find the root of the function\n",
    "@jax.jit\n",
    "def find_fixed_point(R0: float, k: float, x0: float = 0.5, tol: float = 1e-5, maxiter: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Function to find the fixed point of G_nbinom for given R0 and k values.\n",
    "    \"\"\"\n",
    "    fixed_point_func = lambda x: G_nbinom(x, R0, k)\n",
    "    fpi = FixedPointIteration(fixed_point_fun=fixed_point_func, maxiter=maxiter, tol=tol)\n",
    "    return fpi.run(x0).params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PGF:\n",
    "    def __init__(self, poly_coef):\n",
    "        \"\"\"Initialize a PGF using polynomial coefficients.\"\"\"\n",
    "        self.exponents = jnp.arange(0, len(poly_coef))\n",
    "        self.coefficients = jnp.array(poly_coef)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Evaluate the PGF at x.\"\"\"\n",
    "        return jnp.sum(self.coefficients * jnp.power(x, self.exponents))\n",
    " \n",
    "    def derivative(self, x):\n",
    "        \"\"\"Evaluate the derivative of the PGF at x.\"\"\"\n",
    "        return jnp.sum(self.exponents * self.coefficients * jnp.power(x, self.exponents - 1))\n",
    "\n",
    "\n",
    "def implicit_diff_non_parametric(pgf, u):\n",
    "    \"\"\"Compute SCE using implicit differentiation for non-parametric case.\"\"\"\n",
    "    powers = u ** jnp.arange(len(pgf.coefficients))\n",
    "    p_prime = pgf.derivative(u)\n",
    "    dr_da = -powers / p_prime\n",
    "    return dr_da\n",
    "\n",
    "def fixed_point_solver_non_parametric(coeffs, x0=0.5, tol=1e-10, max_iter=100):\n",
    "    \"\"\"Find root using FixedPointIteration solver for non-parametric case.\"\"\"\n",
    "    def iter_func(x,coeffs):\n",
    "        pgf = PGF(coeffs)\n",
    "        return pgf(x)\n",
    "    \n",
    "    solver = FixedPointIteration(\n",
    "        fixed_point_fun=iter_func,\n",
    "        maxiter=max_iter,\n",
    "        tol=tol,\n",
    "        jit=True,\n",
    "        implicit_diff=True,  # Added this parameter to enable implicit differentiation\n",
    "    )\n",
    "    return solver.run(x0,coeffs).params\n",
    "\n",
    "def find_fixed_point_non_parametric_wrapper(R0,k):\n",
    "    \"\"\"\n",
    "    Wrapper function to find the fixed point for non-parametric case.\n",
    "    \"\"\"\n",
    "    coeffs = nbinom_degree_sequence(R0, k)\n",
    "    x0 = 0.5\n",
    "    tol = 1e-10\n",
    "    max_iter = 100\n",
    "    return fixed_point_solver_non_parametric(coeffs, x0, tol, max_iter)\n",
    "\n",
    "def G_binom_param_to_non_param(R0, k, N_max=300):\n",
    "    \"\"\"\n",
    "    Function to compute the negative binomial degree sequence.\n",
    "    \"\"\"\n",
    "    coeffs = nbinom_degree_sequence(R0, k, N_max)\n",
    "    pgf = PGF(coeffs)\n",
    "    return pgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fixed points for a range of R0 and kappa values\n",
    "R_0_list = jnp.linspace(0.8, 4, 3000)\n",
    "kappa_list = jnp.linspace(0.01,10, 3000)\n",
    "\n",
    "def compute_fixed_points(R0_list, k):\n",
    "    \"\"\"Compute fixed points for a list of R0 values with fixed k\"\"\"\n",
    "    fixed_points = []\n",
    "    for R0 in R0_list:\n",
    "        fp = find_fixed_point(R0, k)\n",
    "        fixed_points.append(fp)\n",
    "    return jnp.array(fixed_points)\n",
    "\n",
    "def implicit_diff_parametric(G: Callable, u: float, R0: float, k: float):\n",
    "    \"\"\"Compute derivative of fixed point u with respect to R0 using implicit differentiation\"\"\"\n",
    "    dG_dR0 = jax.grad(G, argnums=1)(u, R0, k)\n",
    "    dG_du = jax.grad(G, argnums=0)(u, R0, k) \n",
    "    # Return derivative du/dR0\n",
    "    return -dG_dR0 / (dG_du - 1)\n",
    "\n",
    "# Calculate derivatives of fixed points with respect to R0\n",
    "@jax.jit\n",
    "def compute_derivatives(fixed_point, R0, k,PGF_func = None):\n",
    "    \"\"\"Compute derivatives of fixed points with respect to R0 and k\"\"\"\n",
    "    #compute the derivatives of G with respect to u, R0 and k\n",
    "    dG_du, dG_dR0, dG_dk = jax.jacrev(G_nbinom, argnums=(0, 1, 2))(fixed_point, R0, k)\n",
    "   \n",
    "    # Calculate the derivatives as the gradient norm \n",
    "    sce_R0 = jnp.abs(dG_dR0 / (dG_du - 1))\n",
    "    sce_k = jnp.abs(dG_dk / (dG_du - 1))\n",
    "    return sce_R0, sce_k\n",
    "\n",
    "# def compute_derivatives_non_parametric(fixed_point, R0, k):\n",
    "#     \"\"\"Compute derivatives of fixed points with respect to R0 and k\"\"\"\n",
    "#     #compute the derivatives of G with respect to u, R0 and k\n",
    "#     dG_du, dG_dR0, dG_dk = jax.jacrev(G_nbinom_, argnums=(0, 1, 2))(fixed_point, R0, k)\n",
    "   \n",
    "#     # Calculate the derivatives as the gradient norm \n",
    "#     sce_R0 = jnp.abs(dG_dR0 / (dG_du - 1))\n",
    "#     sce_k = jnp.abs(dG_dk / (dG_du - 1))\n",
    "#     return sce_R0, sce_k\n",
    "    \n",
    "\n",
    "\n",
    "# Calculate fixed points and their derivatives for a range of R0 and kappa values\n",
    "# R_0_list = jnp.linspace(0.1, 2, 100)\n",
    "# kappa_list = jnp.linspace(0.1, 2, 100)\n",
    "\n",
    "# Create meshgrid for parameter space\n",
    "R0_grid, k_grid = jnp.meshgrid(R_0_list, kappa_list, indexing='ij')\n",
    "\n",
    "# Calculate fixed points using vectorization\n",
    "@jax.vmap\n",
    "def row_fixed_points(r0_row, k_row):\n",
    "    return jax.vmap(lambda rr, kk: find_fixed_point(rr, kk))(r0_row, k_row)\n",
    "\n",
    "fp = row_fixed_points(R0_grid, k_grid)\n",
    "\n",
    "# Initialize arrays for derivatives\n",
    "derivatives_R0 = jnp.zeros_like(fp)\n",
    "derivatives_k = jnp.zeros_like(fp)\n",
    "\n",
    "\n",
    "compute_derivatives_partial = partial(compute_derivatives, PGF_func=G_binom_param_to_non_param)\n",
    "\n",
    "# Define a function to compute derivatives for a single point\n",
    "@jax.jit\n",
    "def compute_single_derivative(r0, k, fixed_pt):\n",
    "    return compute_derivatives(fixed_pt, r0, k)\n",
    "\n",
    "# Vectorize the computation over rows\n",
    "@jax.vmap\n",
    "def compute_row_derivatives(r0_row, k_row, fp_row):\n",
    "    return jax.vmap(lambda r, k, f: compute_single_derivative(r, k, f))(r0_row, k_row, fp_row)\n",
    "\n",
    "\n",
    "\n",
    "# Apply the vectorized function to compute derivatives\n",
    "derivatives = compute_row_derivatives(R0_grid, k_grid, fp)\n",
    "derivatives_R0 = derivatives[0]\n",
    "derivatives_k = derivatives[1]\n",
    "\n",
    "# data = {\n",
    "#     'R0': np.repeat(R_0_list, len(kappa_list)),\n",
    "#     'kappa': np.tile(kappa_list, len(R_0_list)),\n",
    "#     'fixed_point': fp.flatten(),\n",
    "#     'derivative_R0': derivatives_R0.flatten(),\n",
    "#     'derivative_kappa': derivatives_k.flatten()\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df['S'] =  1- df['fixed_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74622afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_derivatives(0.1,0.1,0.1,PGF_func = G_binom_param_to_non_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a925f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a heatmap to visualize the sensitivity\n",
    "plt.figure(figsize=(12, 10))\n",
    "im = plt.pcolormesh(R0_grid, k_grid, derivatives_R0, cmap='viridis', shading='auto')\n",
    "plt.colorbar(im, label='Sensitivity to R₀')\n",
    "plt.xlabel('R₀')\n",
    "#plt.yscale('log')\n",
    "plt.ylabel('κ')\n",
    "plt.title('Sensitivity of Fixed Points to R₀ Changes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee48c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all the resutls in a dataframe \n",
    "data = {\n",
    "    'R0': np.repeat(R_0_list, len(kappa_list)),\n",
    "    'kappa': np.tile(kappa_list, len(R_0_list)),\n",
    "    'fixed_point': fp.flatten(),\n",
    "    'derivative_R0': derivatives_R0.flatten(),\n",
    "    'derivative_kappa': derivatives_k.flatten()\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['S'] =  1- df['fixed_point']\n",
    "\n",
    "#maximum_sce_by_kappa = df.groupby('kappa').agg(max_sce = ('derivative_R0','max'))\n",
    "argmax_sce_by_kappa = df.groupby('kappa').agg(argmax_sce = ('derivative_R0','idxmax'))\n",
    "\n",
    "df_r0_kappa = df.pivot(index='kappa', columns='R0', values='derivative_R0')\n",
    "\n",
    "\n",
    "r0_maxs = np.max(df_r0_kappa, axis=1) # R_0 maxes \n",
    "r0_maxs_indices = np.argmax(df_r0_kappa, axis=1)\n",
    "kappa_vals = kappa_list[r0_maxs_indices]\n",
    "\n",
    "\n",
    "k_maxs = np.max(df_r0_kappa, axis=0) # R_0 maxes \n",
    "k_maxs_indices = np.argmax(df_r0_kappa, axis=0)\n",
    "r0_vals = R_0_list[k_maxs_indices]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12, 10))\n",
    "ax.scatter(R_0_list, kappa_vals, c = 'C0', s = 1.5,label = 'Max SCE w/r/t R₀')\n",
    "ax.scatter(r0_vals, kappa_list, c = 'C1', s = 1.5,label = 'Max SCE w/r/t κ')\n",
    "#im = ax.pcolormesh(R0_grid, k_grid, derivatives_R0, cmap='Blues', shading='auto')\n",
    "ax.set(yscale='log')\n",
    "ax.axvline(1, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "\n",
    "# plt.scatter(R0_vals[20::5], alpha_vals[r0_maxs_indices[20::5]], linewidths= 1.5, facecolors='none', edgecolors=\"#2CD1C1\")\n",
    "#df.groupby('R0').agg(max_sce = ('derivative_R0','max'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8357259",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12, 10))\n",
    "sns.heatmap(df.pivot(index='R0', columns='kappa', values='S').T, cmap='viridis', ax=ax)\n",
    "ax.invert_yaxis()\n",
    "#ax.set(yscale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12, 10))\n",
    "sns.heatmap(df.pivot(index='R0', columns='kappa', values='derivative_R0').T, cmap='Blues', ax=ax,vmax=0.1)\n",
    "ax.invert_yaxis()\n",
    "ax.set(yscale='log',ylim =(0.01,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4368604",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12, 10))\n",
    "sns.heatmap(df.pivot(index='R0', columns='kappa', values='derivative_kappa').T, cmap='Blues', ax=ax)\n",
    "ax.invert_yaxis()\n",
    "#ax.set(yscale='log',ylim =(0.01,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['derivative_combo'] = np.sqrt(df['derivative_R0']**2 + df['derivative_kappa']**2)\n",
    "fig,ax = plt.subplots(1,1,figsize=(12, 10))\n",
    "sns.heatmap(df.pivot(index='R0', columns='kappa', values='derivative_combo').T, cmap='Blues', ax=ax)\n",
    "ax.invert_yaxis()\n",
    "ax.set(yscale='log',ylim =(0.01,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic_poly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
